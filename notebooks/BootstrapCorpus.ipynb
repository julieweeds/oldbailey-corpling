{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrapping Corpora\n",
    "\n",
    "The corpus generating functionality in words.ipynb allows for corpora with various characteristics to be created.  However, we want to be able randomly generate corpora based on trial i.d. for bootstrapping purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import nlp_tools\n",
    "import spacy,operator\n",
    "nlp=spacy.load('en')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juliewe/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2787: DtypeWarning: Columns (16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "worddatafile=\"../../voa/OBV2/obv_words_v2_28-01-2017.tsv\"\n",
    "trialdatafile=\"../../voa/OBV2/obv_defendants_trials.tsv\"\n",
    "\n",
    "worddata=pd.DataFrame.from_csv(worddatafile,sep='\\t')\n",
    "trialdata=pd.DataFrame.from_csv(trialdatafile,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_countdict(alldata):\n",
    "    countdict={}\n",
    "    blacklist=['words','obc_hiscoCode']\n",
    "\n",
    "    for heading in alldata.columns:\n",
    "        #print('Generating counts for ' +heading)\n",
    "        if heading not in blacklist:\n",
    "            countdict[heading]=defaultdict(int)\n",
    "            selection = alldata[heading]\n",
    "            for item in selection:\n",
    "                #print(item)\n",
    "                countdict[heading][item]+=1\n",
    "        else:\n",
    "            #print('skipping')\n",
    "            pass\n",
    "\n",
    "    return countdict\n",
    "\n",
    "def validated(reqlist,valuedata):\n",
    "    \n",
    "    reqdict={}\n",
    "    for (field,value) in reqlist:\n",
    "        \n",
    "        parts=field.split(':')\n",
    "        if len(parts)==1:\n",
    "            if field in valuedata.keys():\n",
    "                if isinstance(value, list):\n",
    "                    ok=[]\n",
    "                    for v in value:\n",
    "                        if v in valuedata[field].keys():\n",
    "                            ok.append(v)\n",
    "                    if len(ok)>0:\n",
    "                        reqdict[field]=ok\n",
    "                elif value in valuedata[field].keys():\n",
    "                    reqdict[field]=value\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            if (parts[1]==\"max\" or parts[1]==\"min\") and parts[0] in valuedata.keys():\n",
    "                \n",
    "                if isinstance(value,list):\n",
    "                   print(\"Error: min and max cannot be list\")\n",
    "                \n",
    "                elif value in valuedata[parts[0]].keys() and isinstance(value,int):\n",
    "                    reqdict[field]=value\n",
    "            \n",
    "    return reqdict\n",
    "\n",
    "\n",
    "def find_trials(worddf,trialdf,reqlist,join='obo_trial'):\n",
    "    \n",
    "    trialreqdict=validated(reqlist,make_countdict(trialdf))\n",
    "    wordsreqdict=validated(reqlist,make_countdict(worddf))\n",
    "    \n",
    "    print(trialreqdict)\n",
    "    print(wordsreqdict)\n",
    "    ok=True\n",
    "    for (req,_value) in reqlist:\n",
    "        if req in trialreqdict.keys() or req in wordsreqdict.keys():\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Requirement {} not satisfied\".format(req))\n",
    "            ok=False\n",
    "     \n",
    "    if not ok:\n",
    "        return None\n",
    "        \n",
    "    \n",
    "    trials=trialdf\n",
    "    for req in trialreqdict.keys():\n",
    "        parts=req.split(':')\n",
    "        value =trialreqdict[req]\n",
    "        if len(parts)>1:\n",
    "            if parts[1]=='max':\n",
    "                trials=trials[trials[parts[0]]<=value]\n",
    "            elif parts[1]=='min':\n",
    "                trials=trials[trials[parts[0]]>=value]\n",
    "        elif isinstance(value,list):\n",
    "            trials=trials[trials[req].isin(value)]                  \n",
    "        else:                      \n",
    "            trials=trials[trials[req]==value]\n",
    "            \n",
    "            \n",
    "    selection=[line for line in trials[join]]\n",
    "    return selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap1(wdf,tdf,reqs):\n",
    "    trials=find_trials(wdf,tdf,reqs)\n",
    "    #print(len(trials),trials)\n",
    "    c=bootstrap_corpus(wdf,trials,reqs)\n",
    "    print(c)\n",
    "    \n",
    "\n",
    "def bootstrap_corpus(worddata,trials,reqs):\n",
    "    N=len(trials)\n",
    "    corpus=[]\n",
    "    #N=1\n",
    "    allreqdict=validated(reqs,make_countdict(worddata))\n",
    "    for i in range(0,N):\n",
    "        atrial=random.choice(trials)\n",
    "        wdf=worddata[worddata['obo_trial']==atrial]\n",
    "        for req in allreqdict.keys():\n",
    "            parts=req.split(':')\n",
    "            value=allreqdict[req]\n",
    "            if len(parts)>1:\n",
    "                if parts[1]=='max':\n",
    "                    wdf=wdf[wdf[parts[0]]<=value]\n",
    "                elif parts[1]=='min':\n",
    "                    wdf=wdf[wdf[parts[0]]>=value]\n",
    "            elif isinstance(value,list):\n",
    "                wdf=wdf[wdf[req].isin(value)]\n",
    "            else:\n",
    "                wdf=wdf[wdf[req]==value]\n",
    "            \n",
    "            \n",
    "          \n",
    "        corpus+=[line for line in wdf['words']]\n",
    "    return corpus\n",
    "        \n",
    " \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'year:min': 1800, 'year:max': 1820, 'obv_role': ['def', 'wv']}\n",
      "{'deft_offcat': 'theft', 'year:min': 1800, 'year:max': 1820}\n",
      "['I live at Witton , a little village in the parish of Twickenham.', \"No, I went out at five o'clock in the morning. I left my wife and two children in the house. My wife returned home first.\", \"On the 10th of August, I went out about ten o'clock. I locked the door, and took the key with me. I left nobody in the house. I fastened the window with a wooden-pin. I returned home about half after three in the afternoon, I found the window broken, and set wide open. It was a little sash that goes back, sliding in a groove.\", 'One of the panes were broken. I secured the window that morning with a wooden-pin.', 'Yes, without the pane had been broken, and they had taken out the peg. The window was on the ground floor. The window was large enough to let a man get in.', \"As soon as I got into the door, I found my house robbed, my property was gone, and my box standing open; that box was in my bed-room; there was no lock to the box; there was gone out of the box, two coats, a pair of breeches, a waistcoat, and a black pair of stockings; they were my husband's property. I saw all these things in the morning before I went out.\", \"When they took the prisoner. I have got them here. I saw them on the Wednesday, after the 12th of August, at Isleworth, in Sarah Denyear 's house. The prisoner confessed that he sold them there. The things were delivered to me; these are them. They are the same things that I saw at Mrs. Denyear's. They are my husband's property.\", 'I buy and sell old clothes at Brentford. On Tuesday, the 12th of August, about the middle of the day, the prisoner brought me these clothes. He said his name was Davis, his brother was gone in the Militia, he said in the 6th division. His brother was a brick maker, and lived at Cooling. He had left him these clothes. He offered them for sale. I gave him 20 s. in silver for them.']\n"
     ]
    }
   ],
   "source": [
    "allreqlist=[('deft_offcat','theft'),('year:min',1800),('year:max',1820),('obv_role',['def','wv'])]\n",
    "\n",
    "bootstrap1(worddata,trialdata,allreqlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For a given set of corpora, find the frequency distribution of the k highest frequency words\n",
    "#Output total size of corpus and sorted list of term, frequency pairs\n",
    "\n",
    "def find_hfw_dist(corpora,k=100000):\n",
    "    #add worddicts for individual corpora\n",
    "    #sort and output highest frequency words\n",
    "    #visualise\n",
    "    \n",
    "    sumdict={}\n",
    "    corpussize=0\n",
    "    for acorpus in corpora:\n",
    "        for(key,value) in acorpus.allworddict.items():\n",
    "            sumdict[key.lower()]=sumdict.get(key.lower(),0)+value\n",
    "            corpussize+=value\n",
    "      \n",
    "    print(\"Size of corpus is {}\".format(corpussize))\n",
    "    candidates=sorted(sumdict.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    #print(candidates[:50])\n",
    "    #print(len(sumdict))\n",
    "    #print(sumdict)\n",
    "    return corpussize,candidates[:k]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(corpusA,corpusB,indicatordict):\n",
    "    sizeA,hfwA=find_hfw_dist([corpusA])\n",
    "    sizeB=corpusB.wordtotal\n",
    "    \n",
    "    for (word,freqA) in hfwA:\n",
    "        freqB=corpusB.allworddict.get(word,0)\n",
    "        probA=freqA/sizeA\n",
    "        probB=freqB/sizeB\n",
    "        if probA>probB:\n",
    "            indicatordict[word]=indicatordict.get(word,0)+1\n",
    "    return indicatordict\n",
    "        \n",
    "def bootstrap_compare(corpusAreqs,allreqs=allreqlist,worddata=worddata,trialdata=trialdata,repeats=10,prop=100):\n",
    "    print(\"Finding trials to meet requirements\")\n",
    "    trialsB=find_trials(worddata,trialdata,allreqs)\n",
    "    print(len(trialsB))\n",
    "    trialsA=find_trials(worddata,trialdata,allreqs+corpusAreqs)\n",
    "    print(len(trialsA))\n",
    "    indicatordict={}\n",
    "    for i in range(0,repeats):\n",
    "        print(\"Bootstrapping corpusB repetition {}\".format(i))\n",
    "        corpB=bootstrap_corpus(worddata,trialsB,allreqs)\n",
    "        print(\"Analysing corpus\")\n",
    "        corpusB=nlp_tools.corpus(corpB,nlp,prop=prop,ner=False,loadfiles=False)\n",
    "        for j in range(0,repeats):\n",
    "            print(\"Bootstrapping corpusA repetition {}\".format(j))\n",
    "            corpA=bootstrap_corpus(worddata,trialsA,allreqs+corpusAreqs)\n",
    "            print(\"Analysing corpus\")\n",
    "            corpusA=nlp_tools.corpus(corpA,nlp,prop=prop,ner=False,loadfiles=False)\n",
    "            print(\"Comparing corpora\")\n",
    "            indicatordict=compare(corpusA,corpusB,indicatordict)\n",
    "\n",
    "    print(\"Generating candidates\")\n",
    "    N=repeats*repeats\n",
    "    candidates=[(term,(value+1)/(N+1)) for (term,value) in indicatordict.items()]\n",
    "    sortedlist=sorted(candidates,key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding trials to meet requirements\n",
      "{'year:min': 1800, 'year:max': 1820, 'obv_role': ['def', 'wv']}\n",
      "{'deft_offcat': 'theft', 'year:min': 1800, 'year:max': 1820}\n",
      "38952\n",
      "{'year:min': 1800, 'year:max': 1820, 'obv_role': ['def', 'wv'], 'obc_sex': 'f'}\n",
      "{'deft_offcat': 'theft', 'year:min': 1800, 'year:max': 1820}\n",
      "6995\n",
      "Bootstrapping corpusB repetition 0\n",
      "Analysing corpus\n",
      "Running basic analysis\n",
      "Analysing 100%. Chunks of size 186953\n",
      "Completed 186953 docs (10.000053489665797% complete)\n",
      "Completed 373906 docs (20.000106979331594% complete)\n",
      "Completed 560859 docs (30.00016046899739% complete)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-3514c826ced9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mAreqs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'obc_sex'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcandidates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAreqs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-3e90918b951b>\u001b[0m in \u001b[0;36mbootstrap_compare\u001b[0;34m(corpusAreqs, allreqs, worddata, trialdata, repeats, prop)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcorpB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_corpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworddata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrialsB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Analysing corpus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mcorpusB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp_tools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloadfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrepeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bootstrapping corpusA repetition {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliewe/Documents/workspace/oldbailey/corpling/notebooks/nlp_tools.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ipfiles, nlpmodel, prop, ner, loadfiles)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mipfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unknown\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_analyse_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minitialise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliewe/Documents/workspace/oldbailey/corpling/notebooks/nlp_tools.py\u001b[0m in \u001b[0;36mbasic_analyse_all\u001b[0;34m(self, ner)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mnlpdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_analyse_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplore_ner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlpdoc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliewe/Documents/workspace/oldbailey/corpling/notebooks/nlp_tools.py\u001b[0m in \u001b[0;36mbasic_analyse_single\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mnlpdoc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mnosents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnlpdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliewe/miniconda3/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, tag, parse, entity)\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Areqs=[('obc_sex','f')]\n",
    "candidates=bootstrap_compare(Areqs,repeats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(candidates[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
